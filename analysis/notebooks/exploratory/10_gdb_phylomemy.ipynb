{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Networks and Word Vectors with MeSH Labels\n",
    "=========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext line_profiler\n",
    "# %load_ext memory_profiler\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import datetime\n",
    "from itertools import zip_longest\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "from analysis.src.data.readnwrite import get_data_dir\n",
    "from analysis.src.data.data_utilities import flatten, eval_column, grouper\n",
    "\n",
    "pd.options.display.max_columns = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rhodonite.phylomemetic import PhylomemeticGraph\n",
    "from rhodonite.cooccurrence import CooccurrenceGraph\n",
    "from rhodonite.spectral import association_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_tool.generation import price_network\n",
    "from graph_tool.draw import graph_draw\n",
    "from graph_tool.all import GraphView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Paths\n",
    "# Get the top path\n",
    "data_path = get_data_dir()\n",
    "\n",
    "# Create the path for external data\n",
    "ext_data = os.path.join(data_path, 'external')\n",
    "# Raw data\n",
    "raw_data = os.path.join(data_path, 'raw')\n",
    "# And external data\n",
    "proc_data = os.path.join(data_path, 'processed')\n",
    "# And interim data\n",
    "inter_data = os.path.join(data_path, 'interim')\n",
    "# And figures\n",
    "fig_path = os.path.join(data_path, 'figures')\n",
    "\n",
    "# Get date for saving files\n",
    "today = datetime.utcnow()\n",
    "\n",
    "today_str = \"_\".join([str(x) for x in [today.year,today.month,today.day]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "We are going to load both the GDB and the RWJF Pioneer and Global projects, and join them into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/grichardson/miniconda3/envs/graph-tool/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (1,5,7,10,11,12,13,14,18,19,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "gdb_df = pd.read_csv(os.path.join(raw_data, 'gdb.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwjf_df = pd.read_csv(os.path.join(inter_data, 'rwjf_pioneer_and_global_projects.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to join the other relevant data modules:\n",
    "\n",
    "Dates for GDB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb_dates_df = pd.read_csv(os.path.join(inter_data, 'gdb_dates.csv'))\n",
    "gdb_df = pd.concat([gdb_df, gdb_dates_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MeSH labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb_mesh_df = pd.read_csv(os.path.join(inter_data, 'gdb_mesh_labels.csv'))\n",
    "rwjf_mesh_df = pd.read_csv(os.path.join(inter_data, 'rwjf_mesh_labels.csv'))\n",
    "\n",
    "gdb_df = pd.concat([gdb_df, gdb_mesh_df], axis=1)\n",
    "rwjf_df = pd.concat([rwjf_df, rwjf_mesh_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to remove projects from GitHub as they don't play nicely with MeSH terms, and Crunchbase as they're very short. There are also some projects with null descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb_df = gdb_df[gdb_df['source_id'] != 'GitHub']\n",
    "gdb_df = gdb_df[gdb_df['source_id'] != 'Crunchbase']\n",
    "gdb_df['description'][pd.isnull(gdb_df['description'])] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's concatenate the two sets of projects and extract their descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/grichardson/miniconda3/envs/graph-tool/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "gdb_df = pd.concat([gdb_df, rwjf_df], axis=0)\n",
    "gdb_df.set_index('doc_id', inplace=True)\n",
    "gdb_df = gdb_df.drop_duplicates(subset='description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = list(gdb_df['description'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a MeSH Label Corpus\n",
    "\n",
    "We need to build a corpus of MeSH label transformed documents that is appropriate for the network we want to build. This will require some filtering, however first we should build a vocabulary of all the terms that we have, so that we can reference any of them by a unique ID at any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_mesh_labels = eval_column(gdb_df, 'mesh_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For filtering later, we will calculate the counts of the MeSH labels. We know already that there are some labels which are highly over-represented, and many which occur only once in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_filter(docs, high_threshold=None, low_threshold=None, remove=[], counter=None):\n",
    "    \"\"\"freqency_filter\n",
    "    Filters words from a corpus that occur more frequently than high_threshold\n",
    "    and less frequently than low_threshold.\n",
    "    \n",
    "    Args:\n",
    "        docs (:obj:`list` of :obj:`list`): Corupus of tokenised documents.\n",
    "        high_threshold (int): Upper limit for token frequency\n",
    "        low_threshold (int): Lower limit for token frequency\n",
    "        remove (:obj:`list`): List of terms to remove\n",
    "    \n",
    "    Yields:\n",
    "        doc_filtered (:obj:`list`): Document with elements removed based\n",
    "            on frequency\n",
    "    \"\"\"\n",
    "    docs_filtered = []\n",
    "    if counter is None:\n",
    "        counter = Counter(flatten(docs))\n",
    "    for doc in docs:\n",
    "        doc_filtered = []\n",
    "        for t in doc:\n",
    "            if t in remove:\n",
    "                continue\n",
    "            if high_threshold is not None:\n",
    "                if counter[t] > high_threshold:\n",
    "                    continue\n",
    "            if low_threshold is not None:\n",
    "                if counter[t] < low_threshold:\n",
    "                    continue\n",
    "            doc_filtered.append(t)\n",
    "        docs_filtered.append(doc_filtered)\n",
    "    return docs_filtered\n",
    "\n",
    "def filter_description_labels(description_labels, fn):\n",
    "    return [list(filter(fn, dl)) for dl in description_labels]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Students', 49316),\n",
       " ('Humans', 47839),\n",
       " ('Animals', 18113),\n",
       " ('Research', 17409),\n",
       " ('Goals', 16430),\n",
       " ('Universities', 16126),\n",
       " ('Research Personnel', 13132),\n",
       " ('United States', 12550),\n",
       " ('Female', 10022),\n",
       " ('Brain', 8834),\n",
       " ('Public Health', 7638),\n",
       " ('Child', 6428),\n",
       " ('Faculty', 5329),\n",
       " ('Mathematics', 5255),\n",
       " ('Awards and Prizes', 5209),\n",
       " ('HIV Infections', 5079),\n",
       " ('Fellowships and Scholarships', 4977),\n",
       " ('Polymers', 4968),\n",
       " ('Surveys and Questionnaires', 4793),\n",
       " ('Software', 4689)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh_label_counts = Counter(flatten(description_mesh_labels))\n",
    "mesh_label_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_mesh_labels_filtered = frequency_filter(description_mesh_labels, high_threshold=18000,\n",
    "                                                    low_threshold=5,\n",
    "                                                    remove = \n",
    "                                                    ['Students', 'Humans', 'Animals', 'Research','Goals',\n",
    "                                                     'Universities', 'Research Personnel', 'United States', \n",
    "                                                     'United Kingdom', 'Research', 'Awards and Prizes',\n",
    "                                                     'Faculty', 'Mice', 'Mathematics', 'Fellowships and Scholarships',\n",
    "                                                    'Surveys and Questionnaires'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = Phrases(description_mesh_labels_filtered, min_count=3)\n",
    "bigrammer = Phraser(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_mesh_labels_bigrams = [bigrammer[d] for d in description_mesh_labels_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = Phrases(description_mesh_labels_bigrams)\n",
    "trigrammer = Phraser(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_mesh_labels_trigrams = [trigrammer[d] for d in description_mesh_labels_bigrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_mesh_labels_final = []\n",
    "for d in description_mesh_labels_trigrams:\n",
    "    corrected_d = []\n",
    "    for t in d:\n",
    "        if len(t.split('_')) > 1:\n",
    "            parts = t.split('_')\n",
    "            corrected_d.append(' '.join(sorted(set(parts))))\n",
    "        else:\n",
    "            corrected_d.append(t)\n",
    "    description_mesh_labels_final.append(corrected_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb_df['cooccurrence_labels'] = description_mesh_labels_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb_df_co = gdb_df[gdb_df['cooccurrence_labels'].str.len() > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Projects by Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take the most recent 10 years of projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb_df_co = gdb_df_co[(gdb_df_co['year'] >= 2006) & (gdb_df_co['year'] < 2018)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016.0    6068\n",
       "2015.0    5852\n",
       "2017.0    5129\n",
       "2013.0    4266\n",
       "2014.0    4217\n",
       "2012.0    3916\n",
       "2010.0    3808\n",
       "2009.0    3799\n",
       "2011.0    3377\n",
       "2008.0    3078\n",
       "2007.0    2687\n",
       "2006.0    1048\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdb_df_co['year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Coocurrence Networks\n",
    "\n",
    "From here we will want to create a new set of labelled descriptions where the terms with very high counts and little semantic value are removed, and also those that appear very few times in the corpus. We will also need to map the labels to token IDs which can then act as the vertex values in our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = range(2006, 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary = Dictionary(gdb_df_co['cooccurrence_labels'])\n",
    "gdb_df_co['cooccurrence_ids'] = [dictionary.doc2idx(d) for d in gdb_df_co['cooccurrence_labels']]\n",
    "\n",
    "cooccurrence_ids_split = []\n",
    "for time in times:\n",
    "    cooccurrence_ids_split.append(gdb_df_co[gdb_df_co['year'] == time]['cooccurrence_ids'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_graphs = []\n",
    "for cis in cooccurrence_ids_split:\n",
    "    co = CooccurrenceGraph()\n",
    "    co.from_sequences(cis, dictionary, window_size=2)\n",
    "    co_graphs.append(co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rhodonite.spectral import association_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/grichardson/nesta/rhodonite/src/rhodonite/spectral.py:30: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.multiply(occurrences, occurrences.transpose()))\n"
     ]
    }
   ],
   "source": [
    "association_strengths = [association_strength(co) for co in co_graphs]\n",
    "\n",
    "for a_s, co in zip(association_strengths, co_graphs):\n",
    "    co.ep['association_strength'] = a_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_cfinder import CFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CFINDER'] = '/home/ec2-user/cfinder_linux/CFinder_commandline64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = CFinder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_s_thresh = [np.percentile(co.ep['association_strength'].get_array(), 5) for co in co_graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_graphs_filt = [\n",
    "    GraphView(\n",
    "        co, \n",
    "        efilt=lambda e: co.ep['association_strength'][e] > a_s\n",
    "    ) \n",
    "    for co, a_s in zip(co_graphs, a_s_thresh)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rhodonite.utilities import save_edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time, co in zip(times, co_graphs_filt):\n",
    "    save_edgelist(co, os.path.join(inter_data, 'gdb_co_graph_{}'.format(time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliques = []\n",
    "for time in times:\n",
    "    in_path = os.path.join(inter_data, 'gdb_co_graph_{}'.format(time))\n",
    "    out_path = os.path.join(inter_data, 'gdb_co_cliques_{}'.format(time))\n",
    "    cliques.append(cf.find(i=in_path, o=out_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "clique_sets = [c['vertices'] for c in cliques]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 1897, 4: 69})\n",
      "Counter({3: 7831, 4: 763, 5: 40})\n",
      "Counter({3: 8749, 4: 815, 5: 27})\n",
      "Counter({3: 12805, 4: 2131, 5: 125, 6: 1})\n",
      "Counter({3: 14123, 4: 2850, 5: 292, 6: 18})\n",
      "Counter({3: 11382, 4: 1514, 5: 65, 6: 1})\n",
      "Counter({3: 15283, 4: 2499, 5: 144, 6: 5})\n",
      "Counter({3: 16562, 4: 2983, 5: 225, 6: 7})\n",
      "Counter({3: 17922, 4: 3657, 5: 330, 6: 13})\n",
      "Counter({3: 26258, 4: 7308, 5: 892, 6: 61, 7: 5})\n",
      "Counter({3: 27927, 4: 9695, 5: 1540, 6: 266, 7: 31, 8: 1})\n",
      "Counter({3: 22021, 4: 6187, 5: 789, 6: 48, 7: 1})\n"
     ]
    }
   ],
   "source": [
    "for cs in cliqe_sets:\n",
    "    counter = Counter([len(c) for c in cs])\n",
    "    print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = PhylomemeticGraph()\n",
    "pg.from_communities(\n",
    "    clique_sets,\n",
    "    labels=times,\n",
    "    min_clique_size=4,\n",
    "    workers=14,\n",
    "    parent_limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_f = GraphView(pg, efilt=lambda e: pg.ep['link_strength'][e] > 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rhodonite.phylomemetic import label_ages, label_density, label_emergence, label_special_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "density = label_density(pg, co_graphs, norm=np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.vp['density'] = density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "emergence = label_emergence(pg)\n",
    "pg.vp['emergence'] = emergence\n",
    "branching, merging = label_special_events(pg)\n",
    "pg.vp['branching'] = branching\n",
    "pg.vp['merging'] = merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.save(os.path.join(inter_data, 'gdb_pg_graph.gt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_thresh = GraphView(pg, efilt=lambda e: pg.ep['link_strength'][e] > 0.45)\n",
    "pg_thresh = GraphView(pg_thresh, vfilt=lambda v: v.out_degree() > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.save(os.path.join(inter_data, 'dictionary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Phylomemetic Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = PhylomemeticGraph()\n",
    "pg.load(os.path.join(proc_data, 'gdb_phylomemetic_10102018/gdb_pg_graph.gt'))\n",
    "\n",
    "dictionary = Dictionary.load(os.path.join(proc_data, 'gdb_phylomemetic_10102018/dictionary'))\n",
    "# dictionary.load(os.path.join(proc_data, 'gdb_phylomemetic_10102018/dictionary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rhodonite.tabular import vertices_to_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_thresh = GraphView(pg, efilt=lambda e: pg.ep['link_strength'][e] > 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_community_property(community, prop, agg):\n",
    "    \"\"\"agg_community_property\n",
    "    \n",
    "    Args:\n",
    "        community (:obj:`iter`):\n",
    "        prop (:obj:`PropertyMap`):\n",
    "        agg (function):\n",
    "        \n",
    "    Returns:\n",
    "        agg_prop_val (:obj:`float`):\n",
    "    \"\"\"\n",
    "    prop_vals = []\n",
    "    for i, j in combinations(community, 2):\n",
    "        prop_vals.append(prop[(i, j)])\n",
    "    agg_prop_val = agg(prop_vals)\n",
    "    return agg_prop_val\n",
    "\n",
    "def label_cooccurrence_property(g, co_graphs, prop, agg, norm=None):\n",
    "    \"\"\"label_cooccurrence_property\"\"\"\n",
    "    community_properties = g.new_vertex_property('float')\n",
    "    df = vertices_to_dataframe(pg)\n",
    "    label_groups = df.groupby('label')\n",
    "    for (_, group), co in zip(label_groups, co_graphs):\n",
    "        strengths = [agg_community_property(c, co.ep[prop], agg) for c in group['item']]\n",
    "        \n",
    "        if norm is not None:\n",
    "            strengths = np.array(strengths) / norm(strengths)\n",
    "        for v, d in zip(group['vertex'], strengths):\n",
    "            community_properties[v] = d\n",
    "    return community_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_strength_means = label_cooccurrence_property(pg, co_graphs, 'association_strength', np.mean, norm=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.vp['association_strength_mean'] = association_strength_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_vertice_df = vertices_to_dataframe(pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_vertice_df['_emergence'] = pg_vertice_df['emergence'].map(\n",
    "    {0: 'ephemeral', 1:'emerging', 2: 'steady', 3: 'declining'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>density</th>\n",
       "      <th>emergence</th>\n",
       "      <th>branching</th>\n",
       "      <th>merging</th>\n",
       "      <th>association_strength_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_emergence</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>declining</th>\n",
       "      <td>2014.355821</td>\n",
       "      <td>2.338779</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.785888</td>\n",
       "      <td>0.418636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emerging</th>\n",
       "      <td>2012.412836</td>\n",
       "      <td>2.489536</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.825165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.548716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ephemeral</th>\n",
       "      <td>2012.873137</td>\n",
       "      <td>7.585991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.753727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>steady</th>\n",
       "      <td>2013.327889</td>\n",
       "      <td>1.527844</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.834882</td>\n",
       "      <td>0.820273</td>\n",
       "      <td>0.235351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  label   density  emergence  branching   merging  \\\n",
       "_emergence                                                          \n",
       "declining   2014.355821  2.338779        3.0   0.000000  0.785888   \n",
       "emerging    2012.412836  2.489536        1.0   0.825165  0.000000   \n",
       "ephemeral   2012.873137  7.585991        0.0   0.000000  0.000000   \n",
       "steady      2013.327889  1.527844        2.0   0.834882  0.820273   \n",
       "\n",
       "            association_strength_mean  \n",
       "_emergence                             \n",
       "declining                    0.418636  \n",
       "emerging                     0.548716  \n",
       "ephemeral                    1.753727  \n",
       "steady                       0.235351  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_vertice_df.groupby('_emergence').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
