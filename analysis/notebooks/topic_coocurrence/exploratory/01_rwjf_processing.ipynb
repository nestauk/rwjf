{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RWJF open data analysis\n",
    "\n",
    "We have access to two datasets about the projects that RWJF support:\n",
    "\n",
    "1. Pioneers dataset: Information about grants awarded as part of the Pioneers programme, which focuses on innovations in the USA\n",
    "2. Global dataset: Grants awarsed as part of the Global programme, which focuses on innovations outside the USA\n",
    "3. Open dataset: With information about all their grants\n",
    "\n",
    "1 and 2 are relatively unstructured but contain rich text, whereas 3 is well structured but doesn't have a lot of text.\n",
    "\n",
    "We want to rapidly process these data and analyse them to understand: \n",
    "\n",
    "* What is RWJFs funding portfolio: what topics are they supporting? Where?\n",
    "* Enrich these data with additional information from for example GRID, CrunchBase to map collaboration networks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional imports\n",
    "import os\n",
    "import ratelim\n",
    "import re\n",
    "import io\n",
    "import urllib\n",
    "import codecs\n",
    "import bs4\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from analysis.src.nlp.lda_pipeline import LdaPipeline, CleanTokenize\n",
    "from analysis.src.data.readnwrite import get_data_dir\n",
    "\n",
    "stop = stopwords.words('English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Open a standard set of directories\n",
    "\n",
    "# Paths\n",
    "\n",
    "# Get the top path\n",
    "data_path = get_data_dir()\n",
    "# Create the path for external data\n",
    "ext_data = os.path.join(data_path, 'external')\n",
    "# Raw data\n",
    "raw_data = os.path.join(data_path, 'raw')\n",
    "# And external data\n",
    "proc_data = os.path.join(data_path, 'processed')\n",
    "# And interim data\n",
    "inter_data = os.path.join(data_path, 'interim')\n",
    "# And figures\n",
    "fig_path = os.path.join(data_path, 'figures')\n",
    "\n",
    "# Get date for saving files\n",
    "today = datetime.today()\n",
    "\n",
    "today_str = \"_\".join([str(x) for x in [today.day,today.month,today.year]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load the Global and Pioneers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_meta(project):\n",
    "    '''\n",
    "    This function takes a project and returns the name and the id (if they are available, this is not always the case)  \n",
    "    '''\n",
    "    \n",
    "    if 'ID'  in project:\n",
    "        #Split on the ID string to get the name\n",
    "        name = project.split('ID')[0].strip()\n",
    "        \n",
    "        #Split on the ID string again to get what we want\n",
    "        grant_id = re.sub('[#:]','',project.split('ID')[1].split('\\n')[0].strip()).strip()   \n",
    "    else:\n",
    "        #If there is no ID we split on line breaks\n",
    "        name = project.strip().split('\\n')[0].strip()\n",
    "        grant_id = np.nan\n",
    "\n",
    "    #description = project.split('\\n*')[1]\n",
    "    return([name,grant_id])\n",
    "\n",
    "def flatten_list(my_list):\n",
    "    '''\n",
    "    Turns a nested list into a flat list\n",
    "    '''    \n",
    "    flat = [x for el in my_list for x in el]    \n",
    "    return(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_rwjf_data(file):\n",
    "    '''\n",
    "    This function reads project lists from the RWJF and tidies it up, and returns\n",
    "    a list where each element has the project name, grant id and description\n",
    "    \n",
    "    '''\n",
    "    #Load the data\n",
    "    with open(raw_data + '/' + file, 'r') as myfile:\n",
    "        data=myfile.read()\n",
    "    \n",
    "    #Split it based on the project separator and leave out the links at the top\n",
    "    projects = data.split('\\n________________\\n')[1:]\n",
    "    \n",
    "    #Extract metadata\n",
    "    project_meta = [get_project_meta(x) for x in projects]\n",
    "    \n",
    "    #project_descriptions = [x[2] for x in project_meta]\n",
    "    \n",
    "    #Clean up the project info\n",
    "    projects_clean = [re.sub('\\* ','',re.sub('\\n','',project)).lower() for project in projects]\n",
    "    \n",
    "    return([[x,y,z] for x,y,z in zip(\n",
    "        [x[0] for x in project_meta],\n",
    "        [x[1] for x in project_meta],\n",
    "        projects_clean)])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both files\n",
    "pio = read_rwjf_data('pioneer_grantees.txt')\n",
    "glob = read_rwjf_data('global_grantees.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw_df = pd.DataFrame([x + ['pioneers'] for x in pio] + [x + ['global'] for x in glob], columns=['project',\n",
    "                                                                                'code', 'description', 'source_id'])\n",
    "\n",
    "rw_df.to_csv(os.path.join(inter_data, 'rwjf_pioneer_and_global_projects.csv'), index=False)\n",
    "\n",
    "rw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load the RWJF open grant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grant_data = pd.read_csv(raw_data+'/rwjf_grants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grant_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grant_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unfortunately they don't have the grant ids in their open dataset! \n",
    "\n",
    "pd.Series(flatten_list([[y for y in x[2].split(' ') if y not in stop] for x in pio])).value_counts()[:10]\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
