{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDG Labelling Data Preparation\n",
    "==============================\n",
    "\n",
    "Cleaning of data scraped from [Partnerships for the SDGs](https://sustainabledevelopment.un.org/partnership/browse/) and [RELX Group SDG Resource Centre](https://sdgresources.relx.com/articles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "import json\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import datetime, date\n",
    "\n",
    "from analysis.src.data.readnwrite import get_data_dir\n",
    "from analysis.src.data.data_utilities import flatten, eval_column, grouper\n",
    "\n",
    "pd.options.display.max_columns = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Paths\n",
    "# Get the top path\n",
    "data_path = get_data_dir()\n",
    "\n",
    "# Create the path for external data\n",
    "ext_data = os.path.join(data_path, 'external')\n",
    "# Raw data\n",
    "raw_data = os.path.join(data_path, 'raw')\n",
    "# And external data\n",
    "proc_data = os.path.join(data_path, 'processed')\n",
    "# And interim data\n",
    "inter_data = os.path.join(data_path, 'interim')\n",
    "# And figures\n",
    "fig_path = os.path.join(data_path, 'figures')\n",
    "\n",
    "# Get date for saving files\n",
    "today = datetime.utcnow()\n",
    "\n",
    "today_str = \"_\".join([str(x) for x in [today.year,today.month,today.day]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "We have a raw dataset from each site that was scraped to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partnernship_df = pd.read_csv(os.path.join(raw_data, 'sdg_partnership_projects_scraped.csv'))\n",
    "relx_df = pd.read_json(os.path.join(raw_data, 'sdg_relx_articles.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partnernship_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relx_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaning\n",
    "\n",
    "### 2.1 Partnership Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals_partner = eval_column(partnernship_df, 'goals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals_binary_partner = []\n",
    "for gp in goals_partner:\n",
    "    goals_binary = np.zeros(17).astype('int8')\n",
    "    for i in gp:\n",
    "        goals_binary[int(i) - 1] = 1\n",
    "    goals_binary_partner.append(goals_binary)\n",
    "\n",
    "ohe_goals_partner = pd.DataFrame(goals_binary_partner)\n",
    "ohe_goals_partner.columns = ['goal_{}'.format(i + 1) for i in range(17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_partnership = list(partnernship_df['content'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_partnership[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Looks like the main text cleaning is removing new lines etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_partnership = [cp.replace('\\n', ' ').replace('\\t', ' ').replace('\\r', ' ') for cp in content_partnership]\n",
    "content_partnership = [re.sub(' +', ' ', cp).strip() for cp in content_partnership]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = partnernship_df['timeframe'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This doesn't work...\n",
    "# I stopped trying when I found the date '1/2///2/0/1/9'...\n",
    "\n",
    "def parse_timeframe(tf):\n",
    "    start, end = tf.split(' - ')[:]\n",
    "    start = start.split(': ')[1]\n",
    "    \n",
    "    start = start.replace(',', ', ')\n",
    "    end = end.replace(',', ', ')\n",
    "    \n",
    "    if '/' in start:\n",
    "        start = start.split('/')\n",
    "        if len(start[-1]) == 2:\n",
    "            start[-1] = '20' + start[-1]\n",
    "        start = '/'.join(end)\n",
    "    if '/' in end:\n",
    "        print(start, end)\n",
    "        end = end.split('/')\n",
    "        if len(end[-1]) == 2:\n",
    "            end[-1] = '20' + end[-1]\n",
    "        end = '/'.join(end)\n",
    "        print(start, end)\n",
    "    if (end == 'ongoing') | (end == '-'):\n",
    "        end = date(year=2030, month=1, day=1)\n",
    "        start = pd.to_datetime(start).date()\n",
    "    else:\n",
    "        start = pd.to_datetime(start).date() \n",
    "        end = pd.to_datetime(end).date()\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 RELX Data\n",
    "\n",
    "#### Goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals_relx = relx_df['sdg_goals'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals_binary_relx = []\n",
    "for gp in goals_relx:\n",
    "    goals_binary = np.zeros(17).astype('int8')\n",
    "    for i in gp:\n",
    "        goals_binary[int(i) - 1] = 1\n",
    "    goals_binary_relx.append(goals_binary)\n",
    "\n",
    "ohe_goals_relx = pd.DataFrame(goals_binary_relx)\n",
    "ohe_goals_relx.columns = ['goal_{}'.format(i + 1) for i in range(17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_goals_relx.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_relx = relx_df['content'].values\n",
    "content_relx[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there's a fair amount of special characters here. Let's get rid of 'em."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_relx = [re.sub(r'[^\\x00-\\x7f]',r' ', cr) for cr in content_relx]\n",
    "content_relx = [re.sub(' +', ' ', cr).strip() for cr in content_relx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Joining and Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_clean_df = pd.DataFrame({'content': content_partnership,\n",
    "                                 'source': 'un_sdg_partnerships'})\n",
    "relx_clean_df = pd.DataFrame({'content': content_relx,\n",
    "                              'source': 'relx'})\n",
    "\n",
    "partner_clean_df = partner_clean_df.join(ohe_goals_partner)\n",
    "relx_clean_df = relx_clean_df.join(ohe_goals_relx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.concat([partner_clean_df, relx_clean_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of projects:\", len(clean_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of projects for each goal:\")\n",
    "for c in clean_df.columns:\n",
    "    if 'goal_' in c:\n",
    "        print('{:7} {:>5}'.format(c, sum(clean_df[c])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv(os.path.join(inter_data, 'sdg_projects_and_goals.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
