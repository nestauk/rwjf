{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RWJF Open Project Data EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional imports\n",
    "import os\n",
    "import ratelim\n",
    "import re\n",
    "import io\n",
    "import urllib\n",
    "import codecs\n",
    "import bs4\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from analysis.src.nlp.lda_pipeline import LdaPipeline, CleanTokenize\n",
    "from analysis.src.data.readnwrite import get_data_dir\n",
    "\n",
    "stop = stopwords.words('English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Open a standard set of directories\n",
    "\n",
    "# Paths\n",
    "\n",
    "# Get the top path\n",
    "data_path = get_data_dir()\n",
    "# Create the path for external data\n",
    "ext_data = os.path.join(data_path, 'external')\n",
    "# Raw data\n",
    "raw_data = os.path.join(data_path, 'raw')\n",
    "# And external data\n",
    "proc_data = os.path.join(data_path, 'processed')\n",
    "# And interim data\n",
    "inter_data = os.path.join(data_path, 'interim')\n",
    "# And figures\n",
    "fig_path = os.path.join(data_path, 'figures')\n",
    "\n",
    "# Get date for saving files\n",
    "today = datetime.today()\n",
    "\n",
    "today_str = \"_\".join([str(x) for x in [today.day,today.month,today.year]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Loading and Processing\n",
    "\n",
    "### 1.1 Load the RWJF scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(raw_data+'/rwjf_scraped.json', 'r') as infile:\n",
    "    rwf = json.load(infile)\n",
    "    \n",
    "r_df_messy = pd.concat([pd.Series(x) for x in rwf],axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is what the data looks like. Note the presence of 'Nones' which we want to turn into nans and\n",
    "# line breaks \\n which we want to turn into spaces\n",
    "#NB also the presence of apparently redundant columns. How is amount_awarded different from awarded?\n",
    "r_df_messy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the type of each class. They are mostly strings. We will need to convert the awarded to floats,\n",
    "#Timeframe or awarded on to dates and so forth.\n",
    "r_df_messy.dropna(axis=0).iloc[0,:].apply(lambda x: type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just checking the formats. Looks like the minimum value that RWJ funds is $50K\n",
    "r_df_messy.apply(lambda x: x.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tidying up. Add missing values\n",
    "r_df_messy = r_df_messy.applymap(lambda x: np.nan if (x==None) | (x=='') else x)\n",
    "\n",
    "#Remove \\n \n",
    "#r_df_messy = r_df_messy.applymap(lambda x: re.sub('\\n',' ',x) if type(x)==str else x)\n",
    "\n",
    "#This is what it looks like now\n",
    "r_df_messy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year(date_string):\n",
    "    '''\n",
    "    Extracts the year from a date string\n",
    "    '''\n",
    "    \n",
    "    year = int(date_string.split('/')[-1]) if type(date_string)==str else np.nan\n",
    "    return(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we convert the amounts awarded to numbers, the awarded dates and start dates to dates.\n",
    "\n",
    "r_df_messy['amount_awarded_$'] = r_df_messy['amount_awarded'].apply(lambda x: \n",
    "                                                                  int(re.sub(r'[$,]','',x)) if type(x)==str else np.nan)\n",
    "\n",
    "r_df_messy['awarded_$'] = r_df_messy['awarded'].apply(lambda x: \n",
    "                                                                  int(re.sub(r'[$,]','',x)) if type(x)==str else np.nan)\n",
    "\n",
    "#Topics\n",
    "r_df_messy['topics'] = r_df_messy['topics'].apply(lambda x: x.split('\\n') if type(x)==str else np.nan)\n",
    "\n",
    "#Years are strings\n",
    "r_df_messy['year'] = r_df_messy['year'].apply(lambda x: int(x) if type(x)==str else np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select variables\n",
    "selected_variables = ['grant_number',\n",
    "            'title','about','topics',\n",
    "            'organization','address','website','location',\n",
    "            'year','amount_awarded_$','awarded_$',]\n",
    "\n",
    "\n",
    "rwj = r_df_messy[selected_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory data analysis\n",
    "\n",
    "Let's learn more about these data:\n",
    "\n",
    "* What do different variables mean?\n",
    "* What are the trends in terms of activity?\n",
    "* What organisations are being funded?\n",
    "* In what topics?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do the financials mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amount awarded is present in almost all cases. Is it the same as awarded?\n",
    "rwj[['amount_awarded_$','awarded_$']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot this\n",
    "plt.scatter(rwj['amount_awarded_$'],rwj['awarded_$'],alpha=0.5,color='blue')\n",
    "plt.title('Amounts awarded vs Awarded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Determine what's happening with these two figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the situation with missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_props(df,ct=None):\n",
    "    '''\n",
    "    Utility function which takes a df and returns missing values in each variable as a % of total.\n",
    "    If ct!= None this is a variable to crosstab the missing data against\n",
    "    \n",
    "    '''\n",
    "    if ct==None:\n",
    "        missing = np.round(100*df.apply(lambda x: np.sum(x.isna()))/len(df),3)\n",
    "        \n",
    "    if ct!=None:\n",
    "        missing = {var: df.groupby(ct)[var].apply(lambda x: np.mean(x.isna())) for var in df.columns}\n",
    "    \n",
    "    return(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot missing values\n",
    "missing_props(rwj).sort_values(ascending=False).plot.bar(color='blue',\n",
    "                                                               title='Missing values (%) by variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(nrows=3,figsize=(8,8),sharex=True,sharey=True)\n",
    "\n",
    "missing_props(rwj,'year')['about'].plot.bar(color='blue',ax=ax[0],title='about')\n",
    "missing_props(rwj,'year')['website'].plot.bar(color='blue',ax=ax[1],title='website')\n",
    "missing_props(rwj,'year')['topics'].plot.bar(color='blue',ax=ax[2],title='topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`About` coverage is not so good. `Website` coverage improves in the last 10 years. \n",
    "`topics` coverage has a more or less constant missing rate\n",
    "\n",
    "**Implications** for now: If we wanted to do an analysis using website data we would need to focus in 2010s or explore sources of bias before 2010."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of projects and amounts awarded (including our two measures)\n",
    "\n",
    "#Create a table with totals raised by year\n",
    "raised = pd.concat([rwj['year'].value_counts(),rwj.groupby('year')[['amount_awarded_$','awarded_$']].sum()],axis=1)\n",
    "\n",
    "raised['awarded_per_project'] = raised['awarded_$']/raised['year']\n",
    "\n",
    "#Plot\n",
    "fig,ax = plt.subplots(figsize=(8,10),\n",
    "                      #sharex=True,\n",
    "                      nrows=4)\n",
    "\n",
    "raised['year'].plot(ax=ax[0],title='Project count',color='blue')\n",
    "raised['amount_awarded_$'].plot(ax=ax[1],title='Amount awarded ($)',color='blue')\n",
    "raised['awarded_$'].plot(ax=ax[2],title='Awarded ($)',color='blue')\n",
    "raised['awarded_per_project'].plot.bar(ax=ax[3],title='Awarded per project $',color='blue')\n",
    "\n",
    "[axis.get_xaxis().set_visible(False) for axis in [ax[0],ax[1],ax[2]]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Very strong correlation between years\n",
    "raised.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No clear trend in activity. `amount_awarded` and `awarded` have a very strong correlation. They are picking up the same variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top organisations and domains. This will be important for the scraping analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What are the most 'popular' organisations in the data in terms of number of projects and \n",
    "# amounts raised?\n",
    "\n",
    "#Create a df with the counts / totals raised\n",
    "org_activity = pd.concat([rwj['organization'].value_counts(),\n",
    "                          rwj.groupby('organization')['awarded_$'].sum()],axis=1)\n",
    "\n",
    "#Sort values by number of projects\n",
    "top_organisations = org_activity.sort_values('organization')[-30:]\n",
    "\n",
    "\n",
    "#plot\n",
    "fig,ax = plt.subplots(ncols=2,figsize=(8,8),sharey=True)\n",
    "\n",
    "top_organisations['organization'].plot.barh(ax=ax[0],color='blue')\n",
    "top_organisations['awarded_$'].plot.barh(ax=ax[1],color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of schools of public health and universities. We can look for similar initiatives / groups in other datasets? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the top websites\n",
    "rwj['website'].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Addresses will need to be geocoded. It would be trivial to extract postcodes with a list of US states.\n",
    "rwj['address'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Should check how many of these are not in the US, and if they are not in the US, where are they"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top topics\n",
    "\n",
    "What are the top topics in the data? What are the top words, based on the 'abouts'? What\n",
    "are the funding trends for different areas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(list):\n",
    "    '''\n",
    "    Flatten a list with nested elements\n",
    "    '''\n",
    "    \n",
    "    flat = [x for el in list for x in el]\n",
    "    return(flat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here are the topics. These are interesting labels to consider when looking at health outcomes\n",
    "topic_counts = pd.Series(flatten_list(rwj['topics'].dropna())).value_counts()\n",
    "\n",
    "real_topics = topic_counts[topic_counts>5].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We would want to look at trends: Number of appearances of topics per year\n",
    "#This list comprehension\n",
    "\n",
    "#Flattens a list of topics for a year (i.e. gives the count of topics for that year) and puts in a dataframe\n",
    "year_freq = pd.DataFrame({y:pd.Series(flatten_list(list(rwj.loc[rwj['year']==y,'topics'].dropna()))).value_counts() for y in \n",
    "                          range(2007,2018)}).fillna(0).loc[real_topics].T\n",
    "\n",
    "#Calculate rolling means\n",
    "year_freq_rolling = year_freq.rolling(window=3).mean()\n",
    "\n",
    "#Plot\n",
    "fig,ax = plt.subplots(figsize=(12,5))\n",
    "\n",
    "year_freq_rolling.plot(ax=ax,linewidth=3,cmap='tab20',title='Number of projects per year (3-year Rolling averages)')\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that system-level determinants of health (*social* and *built environment*) and *early childhood development* have become more important. *Childhood obesity* has lost importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I want to create similar graphs but for totals funded. How do we do this?\n",
    "\n",
    "def filter_on_element(df,filter_variable,filter_value):\n",
    "    '''\n",
    "    This function takes a df where one variable filter_var is a list where every list is a nested element \n",
    "    and returns a boolean telling us if the list hasa filter value or not\n",
    "    We need to run this in a df with no missing values.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Simple\n",
    "    \n",
    "    #We can't filter on missing values so we ignore them\n",
    "    \n",
    "    df_with_values = df.dropna(axis=0,subset=[filter_variable])\n",
    "    \n",
    "    #Subset the df with values on the filter variable\n",
    "    filtered_df = df_with_values.loc[[filter_value in items for items in df_with_values[filter_variable]],:]\n",
    "\n",
    "    #Return Boolean.\n",
    "    return(filtered_df)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a complicated list comprehension. Let's see how it works.\n",
    "#For each year, it loops over the topics and creates a one-element named Series with the totals raised\n",
    "#by projects with the topic. It concatenates it over the year, and over all years.\n",
    "\n",
    "awarded_year_topic = pd.concat([pd.concat([pd.Series(\n",
    "    filter_on_element(rwj.loc[rwj.year==y],'topics',topic).groupby('year')['awarded_$'].sum(),\n",
    "    name=topic)for topic in real_topics],axis=1) for y in np.arange(2007,2018)])\n",
    "\n",
    "\n",
    "#Calculate rolling means\n",
    "year_awarded_rolling = awarded_year_topic.rolling(window=3).mean()\n",
    "\n",
    "#Plot\n",
    "fig,ax = plt.subplots(figsize=(12,5))\n",
    "\n",
    "year_awarded_rolling.plot(ax=ax,linewidth=3,cmap='tab20',title='Awarded to project with topic (3-year Rolling averages)')\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlations between topics\n",
    "#Focus on df that has topics\n",
    "rwj_with_topics = rwj.dropna(axis=0,subset=['topics'])\n",
    "\n",
    "#Create a topic boolean\n",
    "topic_bool = pd.concat([pd.Series(\n",
    "    [1 if top in x else 0 for x in rwj_with_topics['topics']],name=top) for top in real_topics],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a similarity metric and visualise\n",
    "#We need to import the metrics\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "#Similarities are the opposite of distances\n",
    "topic_distances = 1- pairwise_distances(topic_bool.T,metric='jaccard')\n",
    "\n",
    "np.fill_diagonal(topic_distances,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "im = ax.imshow(topic_distances,aspect='auto',cmap='seismic')\n",
    "ax.set_xticks(np.arange(0,15))\n",
    "ax.set_xticklabels(topic_bool.T.index,rotation=45,ha='right')\n",
    "\n",
    "ax.set_yticks(np.arange(0,15))\n",
    "ax.set_yticklabels(topic_bool.T.index)\n",
    "\n",
    "fig.colorbar(im)\n",
    "\n",
    "ax.set_title('Similarity between topics based on co-occurrence in projects')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequent topics are more similar. Hard to discern is this is an artifact of the way the projects are labelled or of their actual similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top words\n",
    "\n",
    "And now we focus on words. This will be important because it will determine if we can use NLP on topic descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the abouts\n",
    "rwj_has_ab = rwj.dropna(axis=0,subset=['about'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a tokenised about\n",
    "#Too many chained methods here?\n",
    "\n",
    "#NB we are using 'threshold' to extract phrases from the corpus\n",
    "\n",
    "rwj_has_ab['about_tokenised'] = CleanTokenize(rwj_has_ab['about']).clean().bigram(threshold=100).tokenised\n",
    "\n",
    "rwj_has_ab['token_length'] = [len(x) for x in rwj_has_ab['about_tokenised']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What are the top words\n",
    "token_freqs = pd.Series(flatten_list(rwj_has_ab['about_tokenised']),name='freq').value_counts()\n",
    "\n",
    "#The top words are not very informative\n",
    "token_freqs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(token_freqs.describe())\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(np.sum(token_freqs>10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 55732 tokens in the corpus. The top word is health (unsurprisingly!). The median word appears 2 times\n",
    "and there are 7600 tokens that appear more than 10 times. We might be able to use this in a topic modelling exercise or classification of projects into health areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rwj_has_ab.groupby('year')['token_length'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory topic modelling\n",
    "\n",
    "Here we perform an exploratory topic modelling of the RWJF data. We simply want to map the activities being undertaken.\n",
    "\n",
    "We use a script we have created with a standard LDA pipeline based on Gensim.\n",
    "\n",
    "We will then explore the results using pyLDA viz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('running 1')\n",
    "\n",
    "test_norm = LdaPipeline(rwj_has_ab['about_tokenised']).filter(3).process().fit_lda(\n",
    "    num_topics=50,passes=20,iterations=130)\n",
    "\n",
    "print('running 2')\n",
    "\n",
    "test_tf = LdaPipeline(rwj_has_ab['about_tokenised']).filter(3).process().tfidf().fit_lda(\n",
    "    num_topics=50,passes=20,iterations=130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_norm.lda_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topics are a bit hit and miss. We seem to be picking up health issues rather than health innovations. Perhaps we need more text?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the data using PyLDAvis?\n",
    "\n",
    "Unfortunately pyLDAvis doesn't seem to play nice with JupyterLabs yet. We have to display the visualisations in a different window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will display it separately\n",
    "import pyLDAvis.gensim\n",
    "#pyLDAvis.enable_notebook()\n",
    "\n",
    "#ldavis_norm = pyLDAvis.gensim.prepare(test_norm.lda_model,test_norm.corpus,test_norm.dictionary)\n",
    "#pyLDAvis.save_html(ldavis_norm,fig_path+'/{date}_test_viz.html'.format(date=today_str))\n",
    "\n",
    "#ldavis_tfidf = pyLDAvis.gensim.prepare(test_tf.lda_model,test_tf.corpus,test_tf.dictionary)\n",
    "#pyLDAvis.save_html(ldavis_tfidf,fig_path+'/{date}_test_viz_tfidf.html'.format(date=today_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embedding and document embedding analysis\n",
    "\n",
    "Another option is to cluster the documents using Doc2vec, which will represent each project in a vector space based on the semantic similarity between its words. We can then cluster these documents and extract their top words in order to identify what they are about.\n",
    "\n",
    "Activities: \n",
    "\n",
    "* Train the doc2vec model on the data.\n",
    "* Cluster the docs\n",
    "* Benchmark the clusters\n",
    "* Label the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim import models\n",
    "\n",
    "#This creates a list where every element is a tag (doc title) and a list of words.\n",
    "#We train the model on that\n",
    "sents = [TaggedDocument(tags=[x],words=y) for x,y in zip(rwj_has_ab['title'],rwj_has_ab['about_tokenised'])]\n",
    "\n",
    "#Train model (NB I havent tuned the d2v)\n",
    "d2v = models.Doc2Vec(sents)\n",
    "\n",
    "#Create document vector matrix\n",
    "document_vectors = np.array([d2v.docvecs[t] for t in rwj_has_ab['title']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering analysis\n",
    "\n",
    "We want to cluster the documents.\n",
    "\n",
    "We will build a pipeline to do this. How is it going to work?\n",
    "\n",
    "* Initialise the class with the records (nrows = records, columns=features for clustering)\n",
    "* Input the parameters for grid-search (eg number of clusters, other variables)\n",
    "* Estimate silouhette scores to compare model performance across algorithms and parameters\n",
    "* Return models\n",
    "* Select models\n",
    "* Re-run models for robust allocation of observations to clusters via community detection\n",
    "* Obtain and name clusters (we will create a function that does this based on the salient terms in the cluster group)\n",
    "* We can then explore the occurrence of technology areas across these clusters.\n",
    "* There is no reason why we couldn't cluster the documents using other vector representations (eg topics via\n",
    "LDA etc.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN, AffinityPropagation, MeanShift, SpectralClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "from yellowbrick.cluster.elbow import KElbowVisualizer\n",
    "from yellowbrick.cluster.silhouette import SilhouetteVisualizer\n",
    "from yellowbrick.text import TSNEVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterDecider():\n",
    "    '''\n",
    "    This class is initialised with a df or array where: \n",
    "    \n",
    "        -Rows are the elements we want to cluster\n",
    "        -Columns are the features we want to use for the clustering (might have done dimensionality reduction on them)\n",
    "    \n",
    "    Methods:\n",
    "    \n",
    "        \n",
    "        -grid_search method taking a list of clustering algorithms and parameters to do grid search over\n",
    "        [need to remember to import clustering algorithms]. This involves creating a cartesian product\n",
    "        of algorithms, fitting the models and predicting the labels.\n",
    "    \n",
    "        TODO -evaluation method estimates metrics of clustering performance based on silouhette score. If\n",
    "        we use a word_similarity metric then we will run a custom-made algorithm that estimates the \n",
    "        average distances between salient words in each cluster compared to those in other clusters,\n",
    "        \n",
    "        -Return a dict with all the models we fit, their parameters and scores.\n",
    "        \n",
    "        We will evaluate these manually, and through Yellowbrick.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,records):\n",
    "        '''\n",
    "        Initialise an instance of the object.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        self.records = records\n",
    "    \n",
    "    def grid_search(self,cluster_list):\n",
    "        '''\n",
    "        Loops through the cluster list and creates a grid search based on the parameters\n",
    "        The parameters are in the second element of each cluster, as a tuple \n",
    "        where the first value is the name of the parameter and the rest are \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        #Read the records\n",
    "        records = self.records\n",
    "        \n",
    "        #Store clustering results in a dict\n",
    "        self.clustering = {}\n",
    "        \n",
    "        #We loop over each cluster and create combinations of parameters\n",
    "        for clust in cluster_list:\n",
    "            cl_algo = clust[0]\n",
    "            \n",
    "            #We get the cluster name in a hacky way via regex\n",
    "            cluster_name = re.sub('_','',str(clust[0]).split('.')[2])\n",
    "            \n",
    "            print('running '+cluster_name)\n",
    "            \n",
    "            #This extracts the dictionary of parameters from the clust list\n",
    "            #and creates a cartesian product (all possible combinations of values)\n",
    "            par_comb = list(product(*clust[1].values()))\n",
    "            \n",
    "            #And this turns the cartesian product into a list of dicts with named parameters\n",
    "            par_list = [{par:val for par,val in zip(clust[1].keys(),par_vals)} for par_vals in par_comb]\n",
    "            \n",
    "            #Now we can loop over this list to to run each cluster:\n",
    "            \n",
    "            for parameters in par_list:\n",
    "                #Initialise the cluster and set parameters\n",
    "                cl = cl_algo().set_params(**parameters)\n",
    "                \n",
    "                #Fit the cluster\n",
    "                cl.fit(records)\n",
    "                \n",
    "                #We also want to estimate the silouhette scores etc.\n",
    "                sil_score = silhouette_score(records,cl.labels_)\n",
    "                \n",
    "                #Store results\n",
    "                self.clustering['_'.join([cluster_name]+[k+':'+str(v) for k,v in parameters.items()])]=[\n",
    "                    cl,\n",
    "                    cl.labels_,\n",
    "                    sil_score]\n",
    "            \n",
    "                #We also want to estimate the silouhette scores etc.   \n",
    "                \n",
    "        return(self)\n",
    "                \n",
    "    def cluster_scores(self):\n",
    "        '''\n",
    "        Takes the scores from the clustering algorithms and plots them\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        #Extract scores\n",
    "        scores = pd.DataFrame([{'name':k,'score':v[-1]} for k,v in self.clustering.items()]).sort_values('score')   \n",
    "        \n",
    "        fig,ax = plt.subplots()\n",
    "\n",
    "        scores['score'].plot.bar(ax=ax,color='blue')\n",
    "\n",
    "        ax.set_xticklabels(scores['name'])\n",
    "        ax.set_title('Silouhette scores')\n",
    "        \n",
    "        return(ax)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual_validation(cluster_labels,sort_results=True,print_n='all',subset=False):\n",
    "    '''\n",
    "    This function takes a list of cluster labels and returns some information about their content:\n",
    "    Number of observations, titles, distinctive words...\n",
    "    \n",
    "    We can ask it to sort the data (start with the biggest clusters) and limit the numbers\n",
    "    that are printed (if we have lots). We can also ask it to print a subset of the clusters\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    rwj_clust = pd.concat([rwj_has_ab[['title','about_tokenised']]])\n",
    "    rwj_clust['cluster'] = cluster_labels\n",
    "\n",
    "    if sort_results == True:\n",
    "    #If we want to present the results labelled\n",
    "        cluster_labels = pd.Series(cluster_labels).value_counts().index\n",
    "    \n",
    "    else:\n",
    "        cluster_labels = sorted(list(set(cluster_labels)))\n",
    "    \n",
    "    \n",
    "    if subset!=False:\n",
    "        cluster_labels = [x for x in cluster_labels if x in subset]\n",
    "    \n",
    "    if print_n!='all':\n",
    "        '''\n",
    "        Select how many to print\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        cluster_labels = cluster_labels[:print_n]\n",
    "        \n",
    "    \n",
    "    for x in cluster_labels:\n",
    "\n",
    "\n",
    "        rel = rwj_clust.loc[rwj_clust['cluster']==x]\n",
    "\n",
    "        print(x)\n",
    "        print(len(rel))\n",
    "\n",
    "        print(rel.head())\n",
    "\n",
    "        print('\\n')\n",
    "\n",
    "        el_freq = pd.Series(flatten_list(rel['about_tokenised']),name=x).value_counts()[:50]\n",
    "\n",
    "        norm_freq = pd.concat([el_freq,token_freqs],axis=1)\n",
    "        norm_freq['norm'] = norm_freq[x]/norm_freq['freq']\n",
    "\n",
    "        print(norm_freq.sort_values('norm',ascending=False)[:10])    \n",
    "\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = ClusterDecider(document_vectors)\n",
    "\n",
    "clusts= [\n",
    "    #[SpectralClustering,{'n_clusters':np.arange(10,20,2)}],\n",
    "    [KMeans,{'n_clusters':np.arange(15,40,2)}],\n",
    "    #[DBSCAN,{}],\n",
    "    #[MeanShift,{'cluster_all':[True,False]}],\n",
    "    #[AffinityPropagation,{}]\n",
    "         ]\n",
    "\n",
    "cd.grid_search(cluster_list=clusts)\n",
    "\n",
    "cd.cluster_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_labs = cd.clustering['kmeans_n_clusters:15'][1]\n",
    "\n",
    "visual_validation(sel_labs,print_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional processing\n",
    "\n",
    "Currently, the clustering algorithm is picking up programmes with repeated titles.\n",
    "\n",
    "We want to remove those. How do we do it?\n",
    "\n",
    "Idea: cluster documents on their titles using doc2vec and then identify which clusters are\n",
    "most homogeneous (eg average levehnstein distances between all components is lower. \n",
    "We then allocate all documents in 'programme clusters' in there, and redo the clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We tokenise titles\n",
    "titles_tokenised = CleanTokenize(rwj_has_ab['title']).clean().bigram(threshold=100).tokenised\n",
    "\n",
    "#We train the model on that\n",
    "sents_dedupe = [TaggedDocument(tags=[x],words=y) for x,y in zip(rwj_has_ab['title'],titles_tokenised)]\n",
    "\n",
    "#Train model (NB I havent tuned the d2v)\n",
    "d2v_title = models.Doc2Vec(sents_dedupe)\n",
    "\n",
    "#Create document vector matrix\n",
    "document_vectors_titles = np.array([d2v_title.docvecs[t] for t in rwj_has_ab['title']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the clustering as before\n",
    "cd_titles = ClusterDecider(document_vectors_titles)\n",
    "\n",
    "clusts= [\n",
    "    #[SpectralClustering,{'n_clusters':np.arange(10,20,2)}],\n",
    "    [KMeans,{'n_clusters':np.arange(30,80,5)}],\n",
    "    #[DBSCAN,{}],\n",
    "    #[MeanShift,{'cluster_all':[True,False]}],\n",
    "    #[AffinityPropagation,{}]\n",
    "         ]\n",
    "\n",
    "cd_titles.grid_search(cluster_list=clusts)\n",
    "\n",
    "cd_titles.cluster_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to allocate 'repeated' clusters (with the same title) to the same cluster and normalise.\n",
    "\n",
    "Otherwise any cluster analysis or topic modelling we do is going to keep picking up those repeated clusters\n",
    "\n",
    "We identify what these clusters are with the mean/variance distance between observations and the cluster centroid (clusters with large/variant distances will be more dispersed than those with small/invariant distances, and less likely to contain repeated programmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cluster = cd_titles.clustering['kmeans_n_clusters:60'][0]\n",
    "\n",
    "#For each cluster, we will calculate distance mean and variance between all observations and the centre.\n",
    "\n",
    "container = []\n",
    "\n",
    "for clust in list(set(test_cluster.labels_)):\n",
    "    #print(clust)\n",
    "    # Find the document vectors in the cluster\n",
    "    \n",
    "    #Subset the document vectors to get those in the cluster\n",
    "    vectors = np.array(document_vectors_titles)[[val==clust for val in test_cluster.labels_],:]\n",
    "    \n",
    "    size = len(vectors)\n",
    "    \n",
    "    #print(vectors.shape)\n",
    "    \n",
    "    #Extract the centroid\n",
    "    centroid = test_cluster.cluster_centers_[x]\n",
    "    \n",
    "    #print(centroid)\n",
    "    \n",
    "    #Calculate all distances\n",
    "    distances = pairwise.cosine_distances(vectors,centroid.reshape(1,-1))\n",
    "    \n",
    "    #print(distances.shape)\n",
    "    \n",
    "    #Calculate distance mean and variance\n",
    "    median = np.median(distances)\n",
    "    \n",
    "    variance = np.round(np.var(distances),3)\n",
    "    \n",
    "    container.append([clust,size,median,variance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_var = [x[0] for x in container if x[3]==0]\n",
    "non_zero_var = [x[0] for x in container if x[0] not in zero_var]\n",
    "\n",
    "#non_zero_var = [x[0] for x in container if x[0] not in zero_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_validation(cd_titles.clustering['kmeans_n_clusters:60'][1],sort_results=False,\n",
    "                  subset=zero_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok - this seems to be picking up the 'duplicate' programmes. Maybe we can wrap them up together and redo the \n",
    "cluster analysis"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
