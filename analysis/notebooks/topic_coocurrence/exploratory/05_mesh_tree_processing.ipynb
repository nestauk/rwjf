{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MeSH Descriptors\n",
    "================\n",
    "\n",
    "This notebook contains code to parse and clean the health and medical terms from the NIH Medical Subject Headings. The original files can be found on their FTP site [here](ftp://nlmpubs.nlm.nih.gov/online/mesh/MESH_FILES/xmlmesh/).\n",
    "\n",
    "There are some existing resources for dealing with MeSH files. These include:\n",
    "\n",
    "* [Working with MeSH Files in Python](https://code.tutsplus.com/tutorials/working-with-mesh-files-in-python-linking-terms-and-numbers--cms-28587) - a rudimentary approach to parsing the available .bin files.\n",
    "* [mesh-tree](https://github.com/scienceai/mesh-tree) - a Java library that parses and provides many useful functions for handling MeSH files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import xmltodict\n",
    "from datetime import datetime\n",
    "\n",
    "pd.options.display.max_colwidth = 100\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#NB I open a standard set of directories\n",
    "\n",
    "#Paths\n",
    "\n",
    "#Get the top path\n",
    "top_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "#Create the path for external data\n",
    "ext_data = os.path.join(top_path,'data/external')\n",
    "\n",
    "#Raw path (for html downloads)\n",
    "\n",
    "raw_data = os.path.join(top_path,'data/raw')\n",
    "\n",
    "#And external data\n",
    "proc_data = os.path.join(top_path,'data/processed')\n",
    "\n",
    "fig_path = os.path.join(top_path,'reports/figures')\n",
    "\n",
    "#Get date for saving files\n",
    "today = datetime.utcnow()\n",
    "\n",
    "today_str = \"_\".join([str(x) for x in [today.month, today.day, today.year]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1 - xmltodict\n",
    "\n",
    "This approach uses the very handy `xmltodict` library, which unsurprisingly parses an XML file into a Python dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ext_data + '/desc2018.xml', 'r') as f:\n",
    "    desc_2018_xml = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_2018_json = xmltodict.parse(desc_2018_xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This essentially does everything that we need. From here we can create maps between various attributes of the terms, to use for analysis. \n",
    "\n",
    "As there is no Python API for interfacing with the MeSH services, a useful thing to do might be to create a wrapper class for the MeSH tree. An idea of how this might look and be used is shown here. It would essentially serve as a class to download and parse the latest MeSH files, and to provide convenience functions for creating mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeSHDescriptors():\n",
    "    def __init__(self, mesh_descriptor_dict=None, file=None, url=None):\n",
    "        \"\"\"MeSHDescriptors\n",
    "        Read, parse or download MeSH descriptor XML files.\n",
    "        \"\"\"\n",
    "        if mesh_descriptor_dict is not None:\n",
    "            self.descriptors = mesh_descriptor_dict\n",
    "        elif file is not None:\n",
    "            self.descriptors = self.read_mesh_xml(file)\n",
    "        elif url is not None:\n",
    "            self.descriptors = self.read_remote_xml(file)\n",
    "    \n",
    "    def read_mesh_xml(self, file):\n",
    "        \"\"\"read_mesh_xml\n",
    "        Reads and parses from XML file.\n",
    "        \"\"\"\n",
    "        with open(file, 'rb') as f:\n",
    "            desc_2018_xml = f.read()\n",
    "        self.descriptors = xmltodict.parse(desc_2018_xml)\n",
    "    \n",
    "    def descriptor_ui_2_tree_number(self):\n",
    "        \"\"\"descriptor_ui_2_tree_number\n",
    "        Create a mapping between DescriptorUI and TreeNumber fields.\n",
    "        \"\"\"\n",
    "        mapper = {}\n",
    "        for d in self.descriptors['DescriptorRecordSet']['DescriptorRecord']:\n",
    "            k = d['DescriptorUI']\n",
    "            if k is not None:\n",
    "                v = d.get('TreeNumberList')\n",
    "                if v is not None:\n",
    "                    v = v.get('TreeNumber')\n",
    "            mapper[k] = v\n",
    "        return mapper\n",
    "    \n",
    "    def to_json(self, file_path=None):\n",
    "        \"\"\"to_json\n",
    "        Serialize the parsed descriptors as a json.\n",
    "        \"\"\"\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(self.descriptors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_descriptors = MeSHDescriptors(desc_2018_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an intial example, we can create a mapping between the _DescriptorUI_ and the _TreeNumber_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dui_tree_number_map = mesh_descriptors.descriptor_ui_2_tree_number()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dui_tree_number_map['D013334']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, it is obvious how we might create further mappings that could be useful to make increased use of the full information available fom the descriptors. To do this, we will export the dict representation of the original XML to JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(proc_data + '/mesh_descriptions_{}.json'.format(today_str), 'w') as f:\n",
    "    json.dump(desc_2018_json, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. An Alternate Route - XML to DataFrame\n",
    "\n",
    "This was the original approach to parsing the MeSH term XML file. It seems irrelavent now that the `xmltodict` method is in use, however I have left it here for interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from \n",
    "# http://www.austintaylor.io/lxml/python/pandas/xml/dataframe/2016/07/08/convert-xml-to-pandas-dataframe/\n",
    "# The original did not account for structures where the last children shared names but not parents as \n",
    "# occurs in this dataset. This gives messier names, but all the information.\n",
    "\n",
    "class XML2DataFrame:\n",
    "\n",
    "    def __init__(self, xml_data):\n",
    "#         parser = ET.XMLParser(encoding=\"utf-8\")\n",
    "#         self.root = ET.fromstring(xml_data, parser=parser)\n",
    "        self.root = ET.XML(xml_data)\n",
    "\n",
    "    def parse_root(self, root):\n",
    "        return [self.parse_element(child, 'Root') for child in iter(root)]\n",
    "\n",
    "    def parse_element(self, element, parent_name, parsed=None):\n",
    "        if parsed is None:\n",
    "            parsed = dict()\n",
    "        for key in element.keys():\n",
    "            parsed[parent_name + key] = element.attrib.get(key)\n",
    "        if element.text:\n",
    "            h_key = parent_name + element.tag\n",
    "#             if h_key in parsed:\n",
    "#                 h_key = h_key + '_1'\n",
    "            parsed[h_key] = element.text\n",
    "        for child in list(element):\n",
    "            self.parse_element(child, element.tag, parsed)\n",
    "        return parsed\n",
    "\n",
    "    def process_data(self):\n",
    "        structure_data = self.parse_root(self.root)\n",
    "        return pd.DataFrame(structure_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_2018_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_2018_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_2018_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_2018_df.drop([\n",
    "       'AllowableQualifierQualifierReferredTo',\n",
    "       'AllowableQualifiersListAllowableQualifier',\n",
    "       'ConceptConceptName', 'ConceptConceptRelationList',\n",
    "       'ConceptListConcept',\n",
    "       'ConceptRelatedRegistryNumberList', 'ConceptRelationListConceptRelation',\n",
    "       'DescriptorRecordAllowableQualifiersList',\n",
    "       'DescriptorRecordConceptList', \n",
    "       'DescriptorRecordDateCreated', 'DescriptorRecordDateEstablished',\n",
    "       'DescriptorRecordDateRevised', 'DescriptorRecordDescriptorName',\n",
    "       'DescriptorRecordPharmacologicalActionList',\n",
    "       'DescriptorRecordPreviousIndexingList',\n",
    "       'DescriptorRecordTreeNumberList', 'DescriptorReferredToDescriptorName',\n",
    "       'PharmacologicalActionDescriptorReferredTo',\n",
    "       'PharmacologicalActionListPharmacologicalAction',\n",
    "       'QualifierReferredToQualifierName',\n",
    "       'RootDescriptorRecord',\n",
    "       'TermDateCreated',\n",
    "       'TermListTerm',\n",
    "       'TermThesaurusIDlist','ECINDescriptorReferredTo',\n",
    "       'ECINQualifierReferredTo',\n",
    "       'ECOUTDescriptorReferredTo',\n",
    "       'ECOUTQualifierReferredTo',\n",
    "       'EntryCombinationECIN',\n",
    "       'EntryCombinationECOUT'],\n",
    "        axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_2018_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_2018_df.rename(columns={'AllowableQualifierAbbreviation': 'QualifierAbbreviation',\n",
    "                            'ConceptConceptUI': 'ConceptUI',\n",
    "                            'ConceptListPreferredConceptYN': 'PreferredConceptYN',\n",
    "                            'ConceptRelationConcept1UI': 'Concept1UI',\n",
    "                            'ConceptRelationConcept1UI': 'Concept2UI',\n",
    "                            'ConceptRelationListRelationName' : 'ConceptRelationName',\n",
    "                            'PreviousIndexingListPreviousIndexing': 'PreviousIndexing',\n",
    "                            'EntryCombinationListEntryCombination': 'EntryCombination',\n",
    "                            'RelatedRegistryNumberListRelatedRegistryNumber': 'RelatedRegistryNumber',\n",
    "                            'SeeRelatedDescriptorDescriptorReferredTo': 'DescriptorReferredTo',\n",
    "                            'SeeRelatedListSeeRelatedDescriptor': 'SeeRelatedDescriptor',\n",
    "                            'TermListConceptPreferredTermYN': 'PreferredTermYN',\n",
    "                            'TermListIsPermutedTermYN': 'IsPermutedTermYN',\n",
    "                            'ThesaurusIDlistThesaurusID': 'ThesaurusID',\n",
    "                            'TreeNumberListTreeNumber': 'TreeNumber'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desc_2018_df['TreeNumber'][pd.isnull(desc_2018_df['TreeNumber'])] = ['U01', 'U02']\n",
    "desc_2018_df = desc_2018_df[~pd.isnull(desc_2018_df['TreeNumber'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MeSH codes resemble the format \"A01.343.124.243\" with up to 12 levels, and where the first letter denotes the coarsest category. We want to know the position in the hierarchy for each word, so we count the number of splits in the code for each term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_splits = []\n",
    "\n",
    "for c in desc_2018_df['TreeNumber'].str.split('.'):\n",
    "    code_splits.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh_tree_codes = ['.'.join(c) for c in code_splits]\n",
    "code_lengths = [len(c) for c in code_splits]\n",
    "max_code_length = max(code_lengths)\n",
    "# desc_2018_df['MeshTreeCode'] = mesh_tree_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_code_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset\n",
    "\n",
    "# for c in desc_2018_df.columns:\n",
    "#     if 'tree' in c:\n",
    "#         desc_2018_df.drop(c, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_2018_df['tree_number_0'] = [c[0][0] for c in code_splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_splits[200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add columns for each code order, so we can group terms together under common codes later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, max_code_length):\n",
    "    tree_lvl_codes = []\n",
    "    for c in code_splits:\n",
    "        if len(c) >= i:\n",
    "            tree_lvl_codes.append('.'.join(c[:i]))\n",
    "        else:\n",
    "            tree_lvl_codes.append(np.nan)\n",
    "    desc_2018_df['tree_number_{}'.format(i)] = tree_lvl_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to map the codes to actual terms, so starting with the 0th level, we map terms obtained manually from the MeSH website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://meshb.nlm.nih.gov/treeView\n",
    "tree_0_map = {\n",
    "    'A': 'anatomy',\n",
    "    'B': 'organisms',\n",
    "    'C': 'diseases',\n",
    "    'D': 'chemicals and drugs',\n",
    "    'E': 'analytical, diagnostic, and therapeutic techniques, and equipment',\n",
    "    'F': 'psychiatry and psychology',\n",
    "    'G': 'phenomena and processes',\n",
    "    'H': 'disciplines and occupations',\n",
    "    'I': 'anthropology, education, sociology, and social phenomena',\n",
    "    'J': 'technology, industry, and agriculture',\n",
    "    'K': 'humanities',\n",
    "    'L': 'information science',\n",
    "    'M': 'named groups',\n",
    "    'N': 'health care',\n",
    "    'V': 'publication characteristics',\n",
    "    'Z': 'geographicals'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_2018_df['tree_string_0'] = desc_2018_df['tree_number_0'].map(tree_0_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the original strings are reversed using commas. To help matching in the documents we should put them in correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desc_2018_df.to_csv(proc_data + '/mesh_codes_cleaned_{}.csv'.format(today_str), index=False)\n",
    "desc_2018_df = pd.read_csv(proc_data + '/mesh_codes_cleaned_{}.csv'.format('5_3_2018')).drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string(string):\n",
    "    string = string.split(', ')\n",
    "    string = ' '.join(string[::-1])\n",
    "    return string.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in desc_2018_df.columns:\n",
    "    if 'String' in c:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_2018_df['ConceptNameString'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_2018_df['DescriptorNameString'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_2018_df['QualifierNameString'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_2018_df['TermString'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_2018_df['ConceptStringProcessed'] = desc_2018_df['ConceptNameString'].apply(lambda x: process_string(x))\n",
    "desc_2018_df['DescriptorStringProcessed'] = desc_2018_df['DescriptorNameString'].apply(lambda x: process_string(x))\n",
    "# desc_2018_df['QualifierStringProcessed'] = desc_2018_df['QualifierNameString'].apply(lambda x: process_string(x))\n",
    "desc_2018_df['TermStringProcessed'] = desc_2018_df['TermString'].apply(lambda x: process_string(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each level, take the tree codes and the processed strings, but only for the ones where the next level up is NaN. This means that only ones which finish at this level of the tree are taken. Set the index of the dataframe to the tree codes and convert to a dict that maps codes to strings. Map that dict on to the codes for the next level up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_string_tree(df, string_column, max_code_length=13):\n",
    "    for i in range(1, max_code_length - 1):\n",
    "        tree_name_map = desc_2018_df[['TreeNumber', string_column]][pd.isnull(desc_2018_df['tree_number_{}'.format(i + 1)])].set_index('TreeNumber').to_dict()\n",
    "        tree_name_map = tree_name_map[string_column]\n",
    "        tree_name_map.pop(np.nan, None)\n",
    "        desc_2018_df['tree_{}_{}'.format(string_column, i)] = desc_2018_df['tree_number_{}'.format(i)].map(tree_name_map, na_action='ignore')\n",
    "    desc_2018_df['tree_{}_{}'.format(string_column, max_code_length - 1)] = np.nan\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['ConceptStringProcessed', 'DescriptorStringProcessed', 'TermStringProcessed']:\n",
    "    desc_2018_df = expand_string_tree(desc_2018_df, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desc_2018_df.to_csv(proc_data + '/mesh_codes_cleaned_{}.csv'.format(today_str), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this there are some broken codes, due to duplicate entries in the tree, but these are relatively few in number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_2018_df['tree_order'] = code_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally export as a json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reoriented = desc_2018_df.set_index('DescriptorRecordDescriptorUI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_string_dict = reoriented.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reoriented.to_json(proc_data + '/mesh_codes_processed_DUI_{}.json'.format(today_str), orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to do a second iteration of this where the tree is not built on one of the terms, but rather the tree numbers.\n",
    "\n",
    "Possible structure that we might want to obtain later:\n",
    "\n",
    "```\n",
    "{'A': {'level': 0,\n",
    "       'term': 'humans',\n",
    "       'children': {'A01': {...\n",
    "                           }\n",
    "                    ...\n",
    "                   }\n",
    "       ... \n",
    "      }\n",
    " ...\n",
    "}\n",
    "                   \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reoriented = desc_2018_df.set_index('TreeNumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_string_dict = reoriented.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reoriented.to_json(proc_data + '/mesh_codes_processed_tree_number_{}.json'.format(today_str), orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_2018_df = pd.read_json('../data/processed/mesh_codes_processed_5_4_2018.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_2018_df.set_index('TreeNumber').to_json('../data/processed/mesh_codes_processed_5_8_2018.json', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_2018_df_2[desc_2018_df_2['ConceptNameString'].str.contains('Volition')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../data/processed/mesh_codes_processed_5_4_2018.json', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'index': 'DescriptorRecordDescriptorUI'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
